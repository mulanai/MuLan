#  <div align="center"> ğŸŒ» MuLan <div>

<div align="center">
<a href=# target="_blank"><img src=https://img.shields.io/badge/Report-b5212f.svg?logo=arxiv height=22px></a>
<a href=http://101.132.98.120:10025/  target="_blank"><img src=https://img.shields.io/badge/%F0%9F%A4%97%20Demo-276cb4.svg height=22px></a>
<!-- <a href=# target="_blank"><img src= https://img.shields.io/badge/Colab-8f2628.svg?logo=googlecolab height=22px></a> -->
<a href=https://huggingface.co/mulanai/mulan-lang-adapter target="_blank"><img src=https://img.shields.io/badge/%F0%9F%A4%97%20Models-d96902.svg height=22px></a>
<!-- <a href=https://github.com/mulanai/MuLan target="_blank"><img src= https://img.shields.io/badge/Page-bb8a2e.svg?logo=github height=22px></a> -->
<a href="https://pypi.org/project/mulankit"><img alt="PyPI - Downloads" src="https://img.shields.io/pypi/v/mulankit?logo=pypi"  height=22px></a>
</div>
<br>

```diff
# pip install mulankit
from diffusers import StableDiffusionPipeline
+ import mulankit

pipe = StableDiffusionPipeline.from_pretrained('Lykon/dreamshaper-8')
+ pipe = mulankit.transform(pipe, 'mulanai/mulan-lang-adapter::sd15_aesthetic.pth')
image = pipe('ä¸€åªè“è‰²çš„ğŸ¶ in the ë°”ë‹¤').images[0]
```

|ä¸€åªè“è‰²çš„ ğŸ¶ in the ë°”ë‹¤ (Dreamshaper-8)| ãƒ¬ã‚´ã‚·ãƒ¥ãƒ¯ãƒ«ãƒ„ã‚§ãƒãƒƒã‚¬ãƒ¼ (SDXL-lightning)| ä¸€åªå¯çˆ±çš„çŒ«å¤´é¹° (MVDream) | æµ·æµªé£æ™¯ (AnimateDiff) |
|--- | ---| --- | --- | 
|![dreamshaper8](assets/dreamshaper8.png) | ![ä¸€åªæˆ´ç€å¸½å­çš„ rabbit](assets/sdxl_lightning.png) | ![ãƒ¬ã‚³ã‚™ã‚¢ãƒ¼ãƒãƒ«ãƒˆã‚™ãƒ»ã‚·ãƒ¥ãƒ¯ãƒ«ãƒ„ã‚§ãƒãƒƒã‚«ã‚™ãƒ¼](assets/mvdream.jpg) | ![æµ·æµª](assets/animatediff.gif)|



## What is it ?

> We present **MuLan**, a versatile framework to equip any diffusion model with multilingual generation abilities natively by *up to 110+ languages* around the world. With properly trained text encoder from noisy data, we demonstrate that MuLan could be *trained on English only data* and support other languages *zero-shot*. Additionally, we introduce **Language Adapter**. A language adapter with *less than 20M parameters*, trained against a frozen denoiser and a text encoder, can be *readily combined with any homologous community models/tools*, such as LoRA, LCM, ControlNet, and IP-Adapter, *without any finetuning*.
> 
> MuLan(æœ¨å…°ï¼‰å¯ä»¥ä½¿ä»»ä½•æ‰©æ•£æ¨¡å‹åŸç”Ÿåœ°æ”¯æŒå¤šè¾¾110å¤šç§è¯­è¨€çš„å›¾åƒ/è§†é¢‘/3Dç”Ÿæˆèƒ½åŠ›ã€‚é€šè¿‡ä½¿ç”¨å¸¦å™ªå£°çš„æµ·é‡æ•°æ®é€‚å½“è®­ç»ƒçš„æ–‡æœ¬ç¼–ç å™¨ï¼Œæˆ‘ä»¬å±•ç¤ºäº†MuLanå¯ä»¥ä»…åœ¨è‹±è¯­æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒå¹¶ä¸”æ”¯æŒå…¶ä»–è¯­è¨€çš„é›¶æ ·æœ¬ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­è¨€é€‚é…å™¨ã€‚ä¸€ä¸ªå…·æœ‰ä¸åˆ°20Må‚æ•°çš„ç®€å•æ˜ å°„ç½‘ç»œï¼Œåœ¨ä¸€ä¸ªå†»ç»“çš„å»å™ªå™¨å’Œæ–‡æœ¬ç¼–ç å™¨ä¸Šè®­ç»ƒï¼Œå³å¯æ— éœ€ä»»ä½•å¾®è°ƒåœ°ä¸ä»»ä½•åŒç±»ç¤¾åŒºæ¨¡å‹/å·¥å…·ï¼ˆå¦‚LoRAã€LCMã€ControlNetå’ŒIP-Adapterï¼‰æ— ç¼ç»“åˆã€‚



https://github.com/mulanai/MuLan/assets/26198430/611ea7ae-b1a8-4c14-8751-34b42175dcca




## News

- [ ] optimize memory usage.
- [ ] release technical report.
- [x] 2024-5-14: release code and models.


## How to use 

We have hosted a gradio demo [here](http://101.132.98.120:10025/).

MuLan supports 
- Base models: Stable Diffusion 1.5, 2.1, XL, Pixart-Alpha/Sigma.
- Downstream models: ControlNet, LCM, LoRA, finetuned models and etc.
- Video models: AnimateDiff.
- 3D models: MVDream.

Please refer to the [USAGE.md](USAGE.md) and [examples](examples/) for more details.


## Model Release

| Model                            | Description | Link                                                                       |
| -------------------------------- | ----|---------------------------------------------------------------------- |
| MuLan-Language-Adapter  | Adapters for SDXL, SD1.5/2.1, Pixart | [hf-model](https://huggingface.co/mulanai/mulan-lang-adapter)         |
| MuLan-Pixart | Full finetuned model | [hf-model](https://huggingface.co/mulanai/mulan-pixart) |

See more at our Huggingface ğŸŒ» [Homepage](https://huggingface.co/mulanai).



## Citation

If you find this repo helpful, please considering citing us.

```bibtex
@article{lai2024mulan,
  title={MuLan: Adapting Multilingual Diffusion Models for 110 + Languages},
  year={2024}
}
```

![Visitors](https://api.visitorbadge.io/api/visitors?path=https%3A%2F%2Fgithub.com%2Fmulanai%2FMuLan&countColor=%23263759&style=flat)


## Acknowledgement

Our work is made possible by the open-source of these great works.

[Stable Diffusion](https://github.com/Stability-AI/stablediffusion) Â· [Pixart-Alpha](https://github.com/PixArt-alpha/PixArt-alpha) Â· [InternVL](https://github.com/OpenGVLab/InternVL) 

If you want to join our WeChat group, please scan the following QR Code to add our assistant as a Wechat friend:

<p align="center"><img width="300" alt="image" src="https://github.com/OpenGVLab/DragGAN/assets/26198430/e3f0807f-956a-474e-8fd2-1f7c22d73997"></p>
